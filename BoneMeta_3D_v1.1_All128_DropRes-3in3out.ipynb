{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lkQzLHipM8Vv"
   },
   "source": [
    "#### Update for v1.1\n",
    "- v1.0 was valid to work\n",
    "- v1.1 added doPrediction for predict whole CT scan as in test setting. \n",
    "\n",
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install monai\n",
    "# !pip install nibabel\n",
    "# !pip install SimpleITK\n",
    "# !pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "244xQcIJg0RL"
   },
   "outputs": [],
   "source": [
    "MODEL_TO_LOAD = ''\n",
    "FN_LOSS = 0\n",
    "LEVELS = 6\n",
    "TRAINING_NAME = f'3D_Unet_DropRes_lv{LEVELS}_All128_3in3out'\n",
    "TB_PREFIX = 'bonemeta_fn_{}'.format(FN_LOSS) + '_{}'.format(TRAINING_NAME)\n",
    "\n",
    "PATCH_SIZE = 128\n",
    "\n",
    "# BATCH_SIZE = 120\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 1000\n",
    "\n",
    "BASE_DIR = '/workspace/BoneMeta_all_128'\n",
    "IMG_FOLDER_NAME = 'images'\n",
    "LABEL_FOLDER_NAME = 'labels_mc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nr6YOqFNyy3v"
   },
   "source": [
    "# Set dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2097,
     "status": "ok",
     "timestamp": 1626888627596,
     "user": {
      "displayName": "이정오",
      "photoUrl": "",
      "userId": "04886549528950007370"
     },
     "user_tz": -540
    },
    "id": "kT6WRrXoI2fe",
    "outputId": "64071a62-3a8c-4633-89f9-e6586f678c73"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/JungOhLee/bonemeta_model.git ./git_clone\n",
    "# !mv  -v ./git_clone/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 587,
     "status": "ok",
     "timestamp": 1626890250549,
     "user": {
      "displayName": "이정오",
      "photoUrl": "",
      "userId": "04886549528950007370"
     },
     "user_tz": -540
    },
    "id": "EmV2m6-yFWDt",
    "outputId": "11802772-72ea-43c3-9334-124985c66b79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_DIR = os.path.join(BASE_DIR, IMG_FOLDER_NAME)\n",
    "LABEL_DIR = os.path.join(BASE_DIR, LABEL_FOLDER_NAME)\n",
    "\n",
    "IMG_FILES = os.listdir(IMG_DIR)\n",
    "LABEL_FILES = os.listdir(LABEL_DIR)\n",
    "\n",
    "def get_img_path(file): \n",
    "    return os.path.join(IMG_DIR, file)\n",
    "\n",
    "def get_label_path(file):\n",
    "    return os.path.join(LABEL_DIR, file)\n",
    "\n",
    "def case_to_file(case):\n",
    "    return case+'.npy'\n",
    "\n",
    "def file_to_case(file_name):\n",
    "    return file_name.split('.')[0]\n",
    "\n",
    "set(IMG_FILES).issubset(LABEL_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/BoneMeta_all_128/images 317\n",
      "/workspace/BoneMeta_all_128/labels_mc 317\n"
     ]
    }
   ],
   "source": [
    "print(IMG_DIR, len(IMG_FILES))\n",
    "print(LABEL_DIR, len(LABEL_FILES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(IMG_FILES)-set(LABEL_FILES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # z축 작은 녀석들만 남기기 \n",
    "# SMALL_Z_CASES = ['000251_20190703_chest', '000356_20191024_chest', '000350_20190927_chest', '000397_20200214_chest', 'BH005_20170701_abdomen', 'BH041_20190201_C-T-L Spine (3D)', 'BH005_20170701_chest', '000355_20190901_abdomen', '000022_20180830_chest', '000244_20190501_abdomen', '000332_20191025_chest', '000019_20181018_chest', 'BH011_20190301_Spine^00_C_Spine_Pre_OP (Adult)', '000019_20190613_chest', 'BH017_20191201_abdomen', '000273_20190531_chest', '000404_20200305_chest', '000286_20190701_abdomen', 'SN015_20190901_chest', '000391_20200216_Thoracic Aorta CT Angio+3D (contrast)', '000262_20190501_abdomen', 'SN013_20190401_chest', '000285_20190807_chest', '000362_20191201_abdomen', '000322_20190913_chest', 'BH057_20191227_chest', '000400_20200210_chest', 'BH064_20200605_abdomen', 'BH034_20190901_chest', '000298_20190726_chest', '000311_20190902_chest', '000396_20200201_abdomen', '000223_20190319_chest', 'BH032_20180701_abdomen', '000291_20190701_abdomen', 'BH045_20181001_abdomen', '000296_20190726_chest', 'BH066_20190525_chest', 'BH010_20161101_chest', '000251_20190701_abdomen', 'SN007_20190701_chest', '000193_20190114_chest', '000262_20190529_chest', '000251_20190429_chest', 'BH060_20200413_chest', '000234_20190419_chest', 'BH040_20200101_CT Angio + 3D Pulmonary artery (Embolism) (2)', 'BH070_20160823_chest', '000316_20190627_chest', '000356_20190901_abdomen', '000383_20200121_chest', 'BH052_20190901_chest', '000450_20200512_chest', '000276_20190604_chest', '000364_20191217_chest', 'BH025_20191101_abdomen', 'BH035_20191101_GU Kidney & bladder CT (3D)', 'BH018_20190801_chest', '000269_20190601_abdomen', 'BH008_20190701_chest', '000332_20191001_abdomen', 'BH043_20191001_abdomen', '000260_20190522_chest', 'BH007_20190801_chest', 'BH067_20191017_chest', '000279_20190614_chest', 'SN004_20190901_chest', 'BH042_20180801_C-T-L Spine (3D)', 'BH099_20200806_abdomen', 'BH055_20200328_chest', 'BH001_20190401_chest', '000162_20180131_chest', 'BH054_20191122_abdomen', '000450_20200501_abdomen', 'BH030_20160101_T-L spine (3D)', '000372_20200107_chest', 'BH069_20200505_chest', 'BH012_20180401_abdomen', 'BH058_20180918_chest', '000404_20200201_abdomen', 'BH048_20190501_chest', '000348_20191201_CT Liver (contrast)', 'BH002_20190701_chest', '000376_20200101_abdomen', '000309_20190801_abdomen', 'SN017_20190701_chest', 'BH029_20200101_chest', 'BH059_20201013_abdomen', '000310_20190801_abdomen', '000272_20190614_chest', 'BH027_20191001_L-spine CT (3D)', 'BH064_20200605_chest', '000350_20191001_abdomen', '000232_20190423_chest', 'BH001_20190501_abdomen', 'BH039_20190601_chest', 'SN008_20190901_chest', '000270_20190608_chest', 'BH091_20200104_chest', '000269_20190604_chest', '000331_20190916_chest', '000325_20190919_chest', '000363_20191222_chest', '000260_20190501_CT Liver (contrast)', '000330_20190926_chest', 'BH072_20200219_abdomen', '000324_20190910_chest', 'BH009_20180301_chest', 'BH028_20190801_chest', 'SN029_20200301_chest', 'BH110_20200616_chest', '000401_20200201_T-Spine+3D CT (noncontrast)', 'SN031_20160501_chest', 'SN005_20191101_chest', '000452_20200513_chest', '000021_20181227_chest', '000236_20190401_abdomen', 'SN002_20190801_chest', '000382_20200129_chest', '000301_20190801_Pulmonary artery CT Angio+3D (contrast)', 'BH015_20190101_chest', 'BH043_20191001_chest', 'BH063_20200519_chest', '000363_20191201_abdomen', '000354_20191001_abdomen', 'BH047_20180901_abdomen', '000079_20180911_Pulmonary artery CT Angio+3D (contrast)', 'BH016_20151001_chest', 'BH061_20190315_abdomen', 'BH014_20181201_chest', '000362_20191214_chest', '000354_20191022_chest', 'SN051_20170401_chest', 'SN036_20190601_chest', 'BH017_20191201_chest', '000282_20190701_abdomen', 'BH023_20191101_chest', '000085_20180829_chest', 'SN019_20190801_chest', '000212_20190324_chest', '000302_20190726_chest', 'BH009_20180301_abdomen', 'BH008_20190701_abdomen', '000301_20190801_abdomen', 'BH015_20190101_abdomen', 'SN028_20160801_chest', '000344_20191125_chest', 'BH014_20181201_abdomen', '000214_20190325_chest', '000386_20200204_chest', '000372_20200101_abdomen', 'BH091_20200104_GU Kidney & bladder CT (3D)', 'SN025_20200401_chest', '000400_20200201_CT Biliary (contrast)', '000255_20190418_chest', 'BH081_20190322_abdomen', '000315_20190820_chest', '000288_20190701_abdomen', '000272_20190601_abdomen', '000322_20190901_abdomen', '000331_20190901_abdomen', 'SN055_20170301_chest', 'BH052_20190901_abdomen', '000310_20190812_chest', '000069_20180319_chest', 'BH024_20190501_abdomen', 'BH021_20181001_abdomen', '000009_20180417_chest', 'BH037_20171101_abdomen', '000002_20180829_chest', '000234_20190401_abdomen', '000262_20190318_chest', 'SN016_20190901_chest', '000232_20190401_abdomen', 'SN056_20170601_Thorax^01_Lung_Cancer_3D (Adult)', '000300_20190801_abdomen', 'BH006_20170801_chest', '000278_20190620_chest', 'BH036_20180301_GU Kidney & bladder CT (3D)', 'BH019_20191101_chest', 'BH004_20191101_chest', '000382_20200101_abdomen', '000242_20190409_chest', 'BH061_20190315_chest', '000080_20180911_chest', '000355_20191023_chest', '000364_20191201_abdomen', 'BH018_20190801_abdomen', '000291_20190718_chest', '000279_20190601_abdomen', '000308_20190826_chest', '000305_20190801_abdomen', 'BH010_20161101_abdomen', 'BH007_20190801_abdomen', 'BH021_20181001_chest', '000396_20200218_chest', '000091_20180504_chest', 'SN042_20170901_chest', '000314_20190827_chest', 'BH031_20160301_CT Angio + 3D Pulmonary artery (Embolism)', 'BH023_20191101_abdomen', '000301_20190827_chest', 'BH062_20201104_chest', 'BH020_20191201_chest', 'BH059_20201019_chest', '000246_20190629_chest', 'BH026_20190601_abdomen', 'BH040_20200101_CT Angio + 3D Pulmonary artery (Embolism)', 'BH034_20190901_abdomen', 'BH099_20200806_chest', 'BH051_20190301_GU Kidney & bladder CT (3D)', '000368_20200101_abdomen', 'BH057_20191227_abdomen', 'BH112_20190201_chest', 'BH024_20190501_chest', 'BH013_20191001_chest', '000309_20190823_chest', '000011_20181207_chest', 'BH020_20191201_abdomen', 'BH027_20191001_chest', '000316_20190715_Spine^L_SPINE (Adult)', '000012_20181214_chest', 'BH032_20180701_chest', 'BH037_20171101_chest', '000285_20190801_abdomen', 'BH038_20160901_CT angio + 3D C-spine(vertebral artery, C1-2)', 'BH072_20200219_chest', 'SN054_20170201_chest', '000048_20190501_abdomen', '000304_20190124_chest', 'BH045_20181001_chest', '000352_20191001_abdomen', 'BH016_20151001_abdomen', 'BH022_20190101_chest', 'BH047_20180901_chest', '000314_20190901_abdomen', 'BH065_20201013_chest', 'BH056_20200721_chest', '000281_20190701_chest', '000025_20180808_chest', '000352_20191017_chest', 'BH012_20180401_chest', '000224_20190228_chest', '000308_20190801_abdomen', '000376_20200114_chest']\n",
    "# SMALL_Z_FILES = [case_to_file(case) for case in SMALL_Z_CASES]\n",
    "# IMG_FILES = list(set(IMG_FILES).intersection(SMALL_Z_FILES))\n",
    "# len(IMG_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILES = ['KH027_20210801_Chest(+).npy', 'SN005_20191101_CT_Chest_+_3D_(contr.npy', 'BH091_20200104_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', '000311_20190902_Chest_CT_(contrast).npy', 'BH023_20191101_Abdomen_&_pelvis_CT_(3D).npy', 'BH076_20180605_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', 'BH121_20200301_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', '000506_20201113_Chest_CT_(contrast).npy', 'BH069_20200505_Chest_CT_(contrast)_+_3D.npy', 'KH039_20210301_Chest_(-)_Routine.npy', 'KH042_20210501_Chest(+).npy', 'BH016_20151001_Abdomen_&_pelvis_CT_(3D).npy', 'BH104_20161219_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', '000362_20191201_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', 'BH035_20191101_GU_Kidney_&_bladder_CT_(3D).npy', '000423_20200401_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', 'SN036_20190601_CT_Chest_+_3D_(contr.npy', 'BH101_20201109_Chest_CT_(Contrast)_+_3D(TS).npy', 'SN025_20200401_CT_Chest_+_3D_(contr.npy', '000364_20191217_Chest_CT_(contrast).npy', 'BH085_20200801_Abdomen_&_pelvis_CT.npy', 'KH023_20210901_Chest(+).npy', 'BH063_20200519_Chest_CT_(Non_contrast)_+_3D(Breast).npy', '000224_20190228_Chest_CT_(contrast).npy', 'BH116_20180606_GU_Abdomen_&_pelvis_CT_(3D).npy', 'BH023_20191101_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', 'BH055_20200328_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', 'KH002_20210301_Abdomen^00_AbdomenRoutine_(Adult).npy', '000370_20200101_CT_Abdomen+Pelvis_Post_(contrast).npy', '000363_20191222_Chest_3DCT_(contrast).npy', 'BH020_20191201_Chest_CT_(Non_contrast)_+_3D.npy', 'BH015_20190101_Chest_CT_(contrast)_+_3D_(Breast_with_other_CT).npy', 'KH016_20191101_Chest(+).npy', '000262_20190501_CT_Abdomen+Pelvis_Post_(contrast).npy', 'BH081_20190322_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', '000282_20190701_CT_Abdomen+Pelvis_Post_(contrast).npy', 'SN042_20170901_CT_Chest_+_3D_(contr.npy', 'BH071_20160826_Chest_CT_(contrast)_+_3D.npy', '000356_20191024_Chest_CT_(contrast).npy', '000162_20180131_Chest_CT_(contrast).npy', '000269_20190601_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', 'BH119_20200303_Abdomen_&_pelvis_CT_(3D).npy', 'BH043_20191001_Abdomen_&_pelvis_CT_(3D).npy', 'SN031_20160501_2-CT_Chest_Lung_cancer.npy', '000530_20210428_Chest_CT_(contrast).npy', 'BH005_20170707_Chest_CT_(contrast)_+_3D_(Breast_with_other_CT).npy', '000363_20191201_CT_Abdomen+Pelvis_Pre-Post_(contrast).npy', 'KH001_20210501_Chest(+).npy', 'KH031_20210801_Chest(+).npy', 'KH010_20201201_Chest(+).npy', '000370_20200117_Chest_CT_(contrast).npy', 'BH037_20171125_Abdomen_&_pelvis_CT_(3D).npy', '000080_20180911_Chest_CT_(contrast).npy', '000262_20190318_Chest_CT_(contrast).npy', 'BH117_20180506_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', 'BH034_20190923_GU_OBGY,Abd-pelvis_CT(pre&post)_(3D).npy', 'BH123_20201023_Abdomen_&_pelvis_CT.npy', 'BH061_20190315_Abdomen_&_pelvis_CT_(3D).npy', 'KH007_20200601_Chest(+)_+_Abdomen_&_Pelvis_(+).npy', 'BH028_20190801_Chest_CT_(contrast)_+_3D.npy', '000085_20180829_Chest_CT_(contrast).npy', '000010_20181214_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', '000435_20200401_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', 'BH019_20191101_Thorax^02_Chest_CON_(Adult).npy', '000386_20200204_Chest_CT_(contrast).npy', '000466_20210128_CT_Abdomen+Pelvis_Post_(contrast).npy', 'BH098_20200626_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', '000325_20190919_Chest_CT_(contrast).npy', '000481_20210305_Thorax^Lung_Pre_(Adult).npy', 'BH108_20180228_Chest_CT_(contrast)_+_3D.npy', 'KH014_20190701_Chest(+).npy', 'SN051_20170401_CT_Chest_+_3D_(contrast_NO_CM).npy', 'BH056_20200721_Chest_CT_(contrast)_+_3D.npy', 'KH014_20190701_IM_Chest(+)_+_Abdomen_&_Pelvis_(+).npy', 'BH091_20200104_GU_Kidney_&_bladder_CT_(3D).npy', 'BH064_20200605_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', 'BH070_20160823_Abdomen_&_pelvis_CT_(3D).npy', 'BH089_20200811_Abdomen_&_pelvis_CT.npy', 'KH043_20210601_Thorax^00_Fl_Chest_Routine_(Adult).npy', 'BH002_20190701_Chest_CT_(Non_contrast)_+_3D.npy', '000279_20190614_Chest_3DCT_(contrast).npy', 'BH031_20160301_CT_Angio_+_3D_Pulmonary_artery_(Embolism).npy', 'BH080_20181210_Abdomen_&_pelvis_CT_(3D).npy', 'BH036_20180301_GU_Kidney_&_bladder_CT_(3D).npy', '000272_20190601_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', '000079_20180911_Pulmonary_artery_CT_Angio+3D_(contrast).npy', '000022_20180830_Chest_CT_(contrast).npy', 'KH026_20210801_Chest(+).npy', 'BH120_20200406_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', 'BH073_20201223_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', 'BH100_20201007_Thorax^02_Chest_CON_(Adult).npy', 'BH086_20190812_Chest_CT_(Contrast)_+_3D(TS).npy', '000322_20190913_Chest_CT_(contrast).npy', 'BH095_20200727_Abdomen_&_pelvis_CT_(3D).npy', 'BH114_20180920_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', 'KH016_20191101_Chest(+)_+_Abdomen_&_Pelvis(+).npy', 'SN028_20160801_CT_Abdomen+Pelvis_3D_(contrast).npy', 'SN055_20170301_CT_Chest_Low_Dose_+.npy', 'KH037_20210401_Chest(+).npy', '000309_20190823_Chest_CT_(contrast).npy', 'SN019_20190801_CT_Abdomen+Pelvis_Ar.npy', '000404_20200201_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', '000528_20210514_Chest_CT_(contrast).npy', '000301_20190827_Chest_CT_(contrast).npy', '000424_20200218_Chest_CT_(contrast).npy', 'BH061_20190315_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', 'BH120_20200304_Chest_CT_(contrast)_+_3D.npy', 'BH105_20160820_Chest_CT_(contrast)_+_3D.npy', 'BH123_20201023_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', 'BH005_20170701_Abdomen_&_pelvis_CT_(3D).npy', 'BH118_20200617_Liver_CT_(LC_or_CLD,_3D).npy', '000262_20190529_Chest_CT_(contrast).npy', 'BH013_20191001_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', '000481_20200722_Chest_CT_(noncontrast).npy', 'BH012_20180401_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', 'BH054_20191122_Abdomen^00_Liver_CT_(Adult).npy', '000011_20181207_CT_Abdomen+Pelvis_Post_(contrast).npy', 'BH059_20201013_Abdomen_&_pelvis_CT.npy', 'BH082_20200416_Chest_CT_(contrast)_+_3D.npy', 'BH010_20161101_Chest_CT_(contrast)_+_3D_(Breast_with_other_CT).npy', 'BH121_20200301_Abdomen_&_pelvis_CT_(3D).npy', 'SN007_20190701_Thorax^05_Chest_Lung_Cancer_3D_(Adult).npy', '000409_20200310_Chest_CT_(contrast).npy', 'BH111_20161020_CT_Angio_+_3D_Coronary,_Chest.npy', 'SN031_20160501_CT_Abdomen+Pelvis_Ar.npy', 'BH118_20200702_Chest_CT_(contrast)_+_3D.npy', '000560_20210706_Chest_CT_(contrast).npy', '000322_20190901_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', '000048_20190501_CT_Abdomen+Pelvis_Uro_(contrast).npy', 'SN019_20190801_CT_Chest_+_3D_(contr.npy', '000506_20201110_CT_Urography_(contrast).npy', '000423_20200407_Chest_CT_(contrast).npy', 'BH032_20180701_Chest_CT_(contrast)_+_3D_(Breast_with_other_CT).npy', 'KH033_20210701_Chest(+).npy', 'BH106_20200613_Abdomen_&_pelvis_CT_(3D).npy', 'BH114_20180920_GU_Kidney_&_bladder_CT_(3D).npy', 'BH008_20190701_Abdomen_&_pelvis_CT_(3D).npy', 'BH067_20191017_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', '000475_20210210_Chest_CT_(contrast).npy', '000417_20200331_Chest_CT_(contrast).npy', 'BH026_20190601_Abdomen_&_pelvis_CT_(3D).npy', '000262_20190319_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', 'BH008_20190701_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', 'BH015_20190101_Abdomen_&_pelvis_CT_(3D).npy', 'BH090_20200924_Abdomen_&_pelvis_CT.npy', 'BH089_20200803_Chest_CT_(Contrast)_+_3D(TS).npy', '000305_20190801_CT_Acute_Abdomen_(contrast).npy', 'BH106_20200613_Chest_CT_(contrast)_+_3D_(Breast_with_other_CT).npy', 'BH120_20200406_Abdomen_&_pelvis_CT_(3D).npy', '000278_20190620_Chest_CT_(contrast).npy', 'BH012_20180401_Abdomen_&_pelvis_CT_(3D).npy', 'SN002_20190801_CT_Chest_+_3D_(contr.npy', 'BH016_20151001_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', '000560_20210706_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', 'KH032_20210701_Chest(+).npy', 'BH064_20200605_Abdomen_&_pelvis_CT_(3D).npy', '000352_20191001_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', '000424_20200312_Chest_CT_(noncontrast).npy', '000269_20190325_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', 'BH107_20200510_Chest_CT_(Contrast)_+_3D(TS).npy', 'SN005_20191001_Abdomen^03_LIVER_(Adult).npy', '000242_20190409_Chest_CT_(contrast).npy', 'BH010_20161101_Abdomen_&_pelvis_CT_(3D).npy', '000291_20190718_Chest_CT_(contrast).npy', '000296_20190726_Chest_CT_(contrast).npy', 'BH081_20190322_Abdomen_&_pelvis_CT_(3D).npy', 'KH030_20210901_Chest_Low-Dose_Screeni.npy', 'KH036_20210401_Chest(+).npy', '000330_20190926_Chest_CT_(contrast).npy', 'KH010_20201201_Chest(+)_+_Abdomen_&_P.npy', '000362_20191214_Chest_CT_(contrast).npy', 'KH028_20210401_Thorax^00_Fl_Chest_Routine_(Adult).npy', 'KH040_20210301_Chest(+).npy', 'SN051_20170401_CT_Abdomen+Pelvis_Arterial+Portal_(contrast).npy', '000400_20200201_CT_Biliary_(contrast).npy', '000368_20200101_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', '000302_20190726_Chest_CT_(contrast).npy', 'BH048_20190501_Chest_CT_(contrast)_+_3D_(Breast_with_other_CT).npy', 'BH078_20200522_Abdomen_&_pelvis_CT_(3D).npy', '000269_20181016_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', '000352_20191017_Chest_CT_(contrast).npy', '000356_20190901_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', 'BH104_20161219_Abdomen_&_pelvis_CT_(3D).npy', 'BH075_20200721_Chest_CT_(Contrast)_+_3D(Breast).npy', 'BH029_20200101_Chest_HRCT_(lung_cancer).npy', '000069_20180319_Chest_CT_(contrast).npy', '000025_20180808_Chest_CT_(contrast).npy', '000270_20190608_Chest_CT_(contrast).npy', '000409_20200301_CT_Biliary_(contrast).npy', 'BH073_20201223_Abdomen_&_pelvis_CT.npy', 'BH113_20170914_Liver_CT_(LC_or_CLD,_3D).npy', '000212_20190324_Chest_CT_(noncontrast).npy', '000494_20210405_Chest_CT_(contrast).npy', 'BH108_20180223_Liver_CT_(LC_or_CLD,_3D).npy', 'SN042_20170901_CT_Abdomen+Pelvis_3D.npy', '000492_20210401_CT_Abdomen+Pelvis_Pre-Post_(contrast).npy', 'KH025_20211001_Chest(+).npy', '000021_20181227_Chest_CT_(contrast).npy', '000332_20191001_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', '000391_20200216_Thoracic_Aorta_CT_Angio+3D_(contrast).npy', '000372_20200101_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', 'SN012_20150801_Abdomen^01_Abdomen_Pelvis_Chest_(Adult).npy', 'SN054_20170201_CT_Chest_Lung_cancer+3D(contrast).npy', '000011_20181207_Chest_CT_(contrast).npy', 'BH070_20160823_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', 'KH024_20211001_Chest(+).npy', 'BH074_20201113_Abdomen^00_Abd_CT_(Adult).npy', '000291_20190701_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', 'BH109_20181210_Chest_CT_(contrast)_+_3D_(Breast_with_other_CT).npy', '000376_20200101_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', 'BH117_20180506_Abdomen_&_pelvis_CT_(3D).npy', 'BH043_20191001_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', 'KH009_20200801_Chest(+).npy', '000376_20200114_Chest_CT_(contrast).npy', '000400_20200210_Chest_CT_(contrast).npy', '000269_20181214_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', 'BH037_20171125_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', 'KH007_20200601_Chest(+).npy', '000025_20180808_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', '000301_20190801_CT_Acute_Abdomen_(contrast).npy', '000309_20190801_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', 'BH076_20180605_GU_Abdomen_&_pelvis_CT_(3D).npy', 'BH007_20190801_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', '000557_20210621_CT_Abdomen+Pelvis_Post_(contrast).npy', 'BH079_20200921_Low_dose_Chest_CT_+_3D(insured).npy', 'BH119_20200227_Chest_CT_(contrast)_+_3D.npy', 'BH066_20190525_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', 'BH045_20181001_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', '000282_20190410_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', 'BH051_20190301_GU_Kidney_&_bladder_CT_(3D).npy', '000557_20210621_Chest_CT_(contrast).npy', 'BH098_20200626_GU_Kidney_&_bladder_CT_(3D).npy', '000304_20190124_CT_Liver_(contrast).npy', '000466_20210125_Chest_CT_(contrast).npy', '000272_20190614_Chest_CT_(contrast).npy', 'KH009_20200801_Chest(+)_+_Abdomen_&_Pelvis_(+).npy', '000541_20210520_Chest_CT_(contrast).npy', '000435_20200420_Chest_CT_(contrast).npy', '000481_20210409_CT_Liver_(contrast).npy', 'BH087_20190314_Abdomen_&_pelvis_CT_(3D).npy', '000533_20210507_CT_Liver_(contrast).npy', '000404_20200305_Chest_CT_(contrast).npy', 'BH007_20190801_Abdomen_&_pelvis_CT_(3D).npy', '000308_20190826_Chest_CT_(contrast).npy', 'KH038_20210401_Chest(+).npy', 'BH034_20190901_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', '000344_20191125_Chest_CT_(contrast).npy', 'BH116_20180606_Chest_CT_(contrast)_+_3D_(Breast_with_other_CT).npy', 'KH002_20210301_Thorax^00_Fl_Chest_Routine_(Adult).npy']\n",
    "VAL_FILES = ['BH099_20200806_Abdomen_&_pelvis_CT.npy', '000019_20181018_Chest_CT_(contrast).npy', 'SN017_20190701_Thorax^05_Chest_Lung_Cancer_3D_(Adult).npy', '000251_20190429_Chest_CT_(contrast).npy', 'SN035_20180101_CT_Stomach+Pelvis_Arterial+Portal(contrast).npy', '000232_20190423_Chest_CT_(contrast).npy', 'BH027_20191001_Chest_CT_(Contrast)_+_3D(TS).npy', 'BH040_20200101_CT_Angio_+_3D_Pulmonary_artery_(Embolism).npy', 'BH024_20190501_Chest_CT_(contrast)_+_3D_(Breast_with_other_CT).npy', 'BH027_20191001_L-spine_CT_(3D).npy', '000286_20190710_[외부_CT_19-07-10]Chest_CT_contrast.npy', '000232_20190401_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', '000251_20190701_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', 'BH099_20200806_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', '000285_20190807_Chest_CT_(contrast).npy', 'BH024_20190501_Abdomen_&_pelvis_CT_(3D).npy', 'BH021_20181001_Abdomen_&_pelvis_CT_(3D).npy', '000316_20190715_Spine^L_SPINE_(Adult).npy', '000193_20190114_Chest_CT_(contrast).npy', 'SN056_20170601_Thorax^01_Lung_Cancer_3D_(Adult).npy', '000316_20190627_Chest_CT_(contrast).npy', '000251_20190703_Chest_CT_(contrast).npy', 'BH110_20200616_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', 'BH006_20170801_Chest_CT_(Contrast)_+_3D(Breast).npy', '000450_20200528_CT_Abdomen+Pelvis_Post_(contrast).npy', 'BH021_20181001_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', 'BH065_20201013_Low_dose_Chest_CT_+_3D(insured).npy', '000019_20190601_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', 'BH060_20200413_Chest_CT_(contrast)_+_3D.npy', 'SN016_20190901_CT_Abdomen+Pelvis_Ar.npy', '000450_20200512_Chest_CT_(contrast).npy', '000285_20190801_CT_Abdomen+Pelvis_Pre-Post_(contrast).npy', 'BH062_20201104_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', '000251_20190429_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', '000019_20190613_Chest_CT_(contrast).npy', 'SN004_20190901_CT_Chest_+_3D_(contrast).npy', '000286_20190701_CT_Abdomen+Pelvis_Dynamic_(contrast).npy']\n",
    "TEST_FILES = ['000214_20190325_Chest_CT_(contrast).npy', '000234_20190401_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', '000234_20190419_Chest_CT_(contrast).npy', '000236_20190401_CT_Abdomen+Pelvis_Post_(contrast).npy', '000244_20190501_CT_Abdomen+Pelvis_Post_(contrast).npy', '000255_20190418_Chest_CT_(contrast).npy', '000260_20190501_CT_Liver_(contrast).npy', '000260_20190522_Chest_CT_(contrast).npy', '000276_20190604_Chest_CT_(contrast).npy', '000281_20190701_Chest_CT_(contrast).npy', '000288_20190701_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', '000298_20190726_Chest_CT_(contrast).npy', '000314_20190827_Chest_CT_(contrast).npy', '000314_20190901_CT_Acute_Abdomen_(contrast).npy', '000354_20191001_CT_Abdomen+Pelvis_Post_(contrast).npy', '000354_20191022_Chest_CT_(contrast).npy', '000355_20190901_CT_Abdomen+Pelvis_Dynamic_(contrast).npy', '000355_20191023_Chest_CT_(contrast).npy', '000383_20200121_Chest_CT_(contrast).npy', 'BH001_20190401_Chest_CT_(Non_contrast)_+_3D.npy', 'BH001_20190501_Abdomen_&_pelvis_CT_(3D).npy', 'BH009_20180301_Abdomen_&_pelvis_CT_(3D).npy', 'BH009_20180301_Chest_CT_(contrast)_+_3D_(TS_with_other_CT).npy', 'BH014_20181201_Abdomen_&_pelvis_CT_(3D).npy', 'BH014_20181201_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', 'BH017_20191201_Abdomen_&_pelvis_CT_(3D).npy', 'BH017_20191201_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', 'BH022_20190101_Thorax^03_Chest_NON_(Adult).npy', 'BH047_20180901_Abdomen_&_pelvis_CT_(3D).npy', 'BH047_20180901_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', 'BH052_20190901_Abdomen_&_pelvis_CT_(3D).npy', 'BH052_20190901_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', 'BH057_20191227_Abdomen_&_pelvis_CT_(3D).npy', 'BH057_20191227_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', 'BH058_20180918_Chest_CT_(contrast)_+_3D.npy', 'BH112_20190201_Abdomen_&_pelvis_CT_(3D).npy', 'BH112_20190201_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy', 'SN016_20190901_CT_Chest_+_3D_(contr.npy', 'SN028_20160801_CT_Chest_+_3D_(contrast).npy']\n",
    "\n",
    "# EXCEPTIONS = ['BH040_20200101_CT Angio + 3D Pulmonary artery (Embolism).npy', 'BH040_20200101_CT Angio + 3D Pulmonary artery (Embolism) (2).npy'] # 모델에서 data info 만들때 가끔 오류남.\n",
    "EXCEPTIONS = '''000273_20190531_Chest_CT_(contrast).npy\n",
    "000439_20200624_Chest_CT_(contrast).npy\n",
    "000557_20210621_Chest_CT_(contrast).npy\n",
    "BH002_20190701_Chest_CT_(Non_contrast)_+_3D.npy\n",
    "BH091_20200104_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy\n",
    "BH091_20200104_Chest_CT_(contrast)_+_3D_(Chest_with_other_CT).npy\n",
    "000350_20191001_CT_Abdomen+Pelvis_Dynamic_(contrast).npy\n",
    "000352_20191017_Chest_CT_(contrast).npy\n",
    "000354_20191022_Chest_CT_(contrast).npy\n",
    "000391_20200216_Thoracic_Aorta_CT_Angio+3D_(contrast).npy\n",
    "BH027_20191001_L-spine_CT_(3D).npy\n",
    "000270_20190601_CT_Abdomen+Pelvis_Dynamic_(contrast).npy\n",
    "000270_20190608_Chest_CT_(contrast).npy\n",
    "BH040_20200101_CT_Angio_+_3D_Pulmonary_artery_(Embolism).npy\n",
    "BH118_20200617_Liver_CT_(LC_or_CLD,_3D).npy\n",
    "000424_20200312_Chest_CT_(noncontrast).npy\n",
    "000424_20200218_Chest_CT_(contrast).npy\n",
    "000325_20190919_Chest_CT_(contrast).npy\n",
    "BH069_20200505_Chest_CT_(contrast)_+_3D.npy'''.split('\\n')\n",
    "\n",
    "TRAIN_FILES = list(set(TRAIN_FILES).intersection(set(IMG_FILES)) - set(EXCEPTIONS))\n",
    "VAL_FILES = list(set(VAL_FILES).intersection(set(IMG_FILES)) - set(EXCEPTIONS))\n",
    "TEST_FILES = list(set(TEST_FILES).intersection(set(IMG_FILES)) - set(EXCEPTIONS))\n",
    "\n",
    "# TRAIN_FILES = TRAIN_FILES[:50]\n",
    "# VAL_FILES = VAL_FILES[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILES = list(set(TRAIN_FILES) - set(VAL_FILES) - set(TEST_FILES))\n",
    "VAL_FILES = list(set(VAL_FILES))\n",
    "TEST_FILES = list(set(TEST_FILES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train: 238\n",
      "val: 35\n",
      "test: 30\n",
      "total: 303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "train: {len(TRAIN_FILES)}\n",
    "val: {len(VAL_FILES)}\n",
    "test: {len(TEST_FILES)}\n",
    "total: {len(TRAIN_FILES + VAL_FILES + TEST_FILES)}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "UNDBJinfPD2q"
   },
   "outputs": [],
   "source": [
    "def adjust_window(image, window):\n",
    "    width = window[0]\n",
    "    level = window[1]\n",
    "    upper = level+width/2\n",
    "    lower = level-width/2\n",
    "    copied_image = image.clip(lower, upper)\n",
    "    copied_image = copied_image-lower\n",
    "    return (copied_image/(upper-lower))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghAI2GSKIofO"
   },
   "source": [
    "# Set dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import time\n",
    "import os, glob\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from augmentation import get_transform\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, case_files=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.case_files = case_files\n",
    "        self.images = [np.load(get_img_path(file)) for file in case_files]\n",
    "        self.labels = [np.load(get_label_path(file)) for file in case_files]\n",
    "        self.windows = [(500,200), (700,400), (1200,400)]\n",
    "\n",
    "    def get_data_info(self):\n",
    "        all_data_info = pd.read_csv(f'{BASE_DIR}/data_info_V_2022_04_20.csv')\n",
    "        case_tuple = tuple([file_to_case(file) for file in self.case_files])\n",
    "        include_idx = all_data_info.Case.str.startswith(case_tuple)\n",
    "        return all_data_info.loc[include_idx]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.case_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.get_case(idx)\n",
    "    \n",
    "    def get_case(self, idx):\n",
    "        patch_image = self.images[idx]\n",
    "        patch_label = self.labels[idx]\n",
    "        return self.process_patch(patch_image, patch_label)\n",
    "\n",
    "    def process_patch(self, patch_image, patch_label):\n",
    "#         patch_image, patch_label = torch.tensor(patch_image, dtype=torch.float32), torch.tensor(patch_label, dtype=torch.bool)\n",
    "#         return self.convert_to_multi_channel_img(patch_image, self.windows), patch_label\n",
    "        augmentation_dict={'flip': True, 'scale':0.2, 'rotate':False,'offset': 0.1, 'noise': 0.1}\n",
    "        transformed_image, transformed_label = get_transform(patch_image, patch_label, augmentation_dict)\n",
    "        return self.convert_to_multi_channel_img(transformed_image, self.windows), transformed_label   \n",
    "    \n",
    "    def convert_to_multi_channel_img(self, image, windows):\n",
    "        adjusted_images = [adjust_window(image, window) for window in windows]\n",
    "        return torch.stack(adjusted_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValDataset(Dataset):\n",
    "    def __init__(self, case_files=None, ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            case_files (string): case filenames\n",
    "        Return:\n",
    "            one whole case\n",
    "\n",
    "        \"\"\"\n",
    "        self.case_files = case_files\n",
    "        self.images = [np.load(get_img_path(file)) for file in case_files]\n",
    "        self.labels = [np.load(get_label_path(file)) for file in case_files]\n",
    "        self.windows = [(500,200), (700,400), (1200,400)]\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.case_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.images[idx], self.labels[idx]\n",
    "        image_tensor = torch.tensor(image, dtype = torch.float32)\n",
    "        multi_channel_image = self.convert_to_multi_channel_img(image_tensor, self.windows)\n",
    "        return multi_channel_image, torch.tensor(label, dtype = torch.bool)\n",
    "    \n",
    "    def change_to_pytorch_coord(self, coord):\n",
    "        # 현재 데이터 저장이 col, row, z 로 되어있음. -> z, row, col로 변경\n",
    "        return [coord[2],coord[1],coord[0]]\n",
    "\n",
    "    def convert_to_multi_channel_img(self, image, windows):\n",
    "        adjusted_images = [adjust_window(image, window) for window in windows]\n",
    "        return torch.stack(adjusted_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_img(img, offset, end, interval):\n",
    "  if end is None:\n",
    "    end = len(img)\n",
    "  else: \n",
    "    if end > len(img): \n",
    "      end = len(img)\n",
    "    if end <= offset:\n",
    "      end = offset + 1\n",
    "  return img[offset:end:interval]\n",
    "\n",
    "def show_numpy_img(np_img, offset=0, end=None, interval=5, title=''): \n",
    "  sliced_img = slice_img(np_img, offset, end, interval)\n",
    "\n",
    "  figsize_per_img = 3\n",
    "  num_col = 5\n",
    "  num_row = int(np.ceil(sliced_img.shape[0] / num_col))\n",
    "  # fig, axs = plt.subplots(num_row, num_col, figsize = (figsize_per_img*num_col, figsize_per_img*num_row))\n",
    "  plt.figure(figsize=(figsize_per_img*num_col, figsize_per_img*num_row))\n",
    "  for i, img in enumerate(sliced_img):\n",
    "    if i >= num_col*num_row:\n",
    "      continue\n",
    "    # axs[i].imshow(img)\n",
    "    plt.subplot(num_row, num_col, i+1)\n",
    "    plt.imshow(img, 'gray')\n",
    "    # plt.title()\n",
    "  plt.suptitle(title)\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "#npy image 정보 보여주기 \n",
    "def show_img_info(np_img):\n",
    "  print('Shape:', np_img.shape)\n",
    "  print('DType:', np_img.dtype)\n",
    "  print('Max:', np_img.max())\n",
    "  print('Min:', np_img.min())\n",
    "  print(np_img)\n",
    "\n",
    "def plot_img_and_label(np_img, label, interval = 5, offset = 0, end=None, figsize_per_image = 5):\n",
    "  sliced_img = slice_img(np_img, offset, end, interval)\n",
    "  sliced_label = slice_img(label, offset, end, interval)\n",
    "  \n",
    "  num_row = len(sliced_img)\n",
    "  num_col = 2\n",
    "\n",
    "  plt.figure(figsize=(figsize_per_image*num_col, figsize_per_image*num_row))\n",
    "\n",
    "  for i in range(0, num_row):\n",
    "    plt.subplot(num_row, num_col, i*num_col+1)\n",
    "    tissue_image = sliced_img[i]\n",
    "    plt.imshow(tissue_image, 'gray')\n",
    "\n",
    "    plt.subplot(num_row, num_col, i*num_col+2)\n",
    "    mask = sliced_label[i]\n",
    "    label_on_tissue = sitk.LabelMapContourOverlay(sitk.Cast(sitk.GetImageFromArray(mask), sitk.sitkLabelUInt8), sitk.GetImageFromArray(tissue_image), opacity=0.7, contourThickness=[2,2], colormap=(0,255,0))\n",
    "    plt.imshow(sitk.GetArrayFromImage(label_on_tissue), 'gray')\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img, label = train_dataset[0]\n",
    "# plot_img_and_label(img[0].type(torch.int16).numpy(), label.type(torch.uint8).numpy())\n",
    "\n",
    "# # plot_img_and_label(*train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ozUJqsdu6gGe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "consumed_time: 1.328372387913987s\n",
      "train: 238\n",
      "val: 35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = time.perf_counter()\n",
    "\n",
    "train_dataset = TrainDataset(TRAIN_FILES)\n",
    "val_dataset = ValDataset(VAL_FILES)\n",
    "\n",
    "elapsed_time = time.perf_counter() - t\n",
    "\n",
    "print(f'''\n",
    "consumed_time: {elapsed_time}s\n",
    "train: {len(train_dataset)}\n",
    "val: {len(val_dataset)}\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "executionInfo": {
     "elapsed": 697,
     "status": "ok",
     "timestamp": 1626890464593,
     "user": {
      "displayName": "이정오",
      "photoUrl": "",
      "userId": "04886549528950007370"
     },
     "user_tz": -540
    },
    "id": "cGOP-nkobJN_",
    "outputId": "73519980-277b-4851-81e4-6fe74bccfe2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efc3e944fd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_train = train_dataset[9]\n",
    "plt.imshow(sample_train[0][2][PATCH_SIZE//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "executionInfo": {
     "elapsed": 492,
     "status": "ok",
     "timestamp": 1626890465081,
     "user": {
      "displayName": "이정오",
      "photoUrl": "",
      "userId": "04886549528950007370"
     },
     "user_tz": -540
    },
    "id": "BhG5M7KJfyx9",
    "outputId": "44e95dda-ebf3-44e2-d662-ab065e2228bc",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efc3e84d4c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample_train[1][PATCH_SIZE//2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IE6jDD9rgy4S"
   },
   "source": [
    "# Dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1626890465082,
     "user": {
      "displayName": "이정오",
      "photoUrl": "",
      "userId": "04886549528950007370"
     },
     "user_tz": -540
    },
    "id": "szCOieSb6tj3",
    "outputId": "06608c71-88c8-4c2b-cadb-e8e46f91c749"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "faTuO1ZW2eN4"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# USE_CUDA = torch.cuda.is_available()\n",
    "USE_CUDA = False\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "# NUM_WORKERS = multiprocessing.cpu_count()\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "def initTrainDl(train_ds, batch_size = BATCH_SIZE):\n",
    "    if USE_CUDA:\n",
    "        batch_size *= torch.cuda.device_count()\n",
    "\n",
    "    train_dl = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=USE_CUDA,\n",
    "        shuffle=True,\n",
    "        drop_last=False # to prevent gradient exploding\n",
    "    )\n",
    "    return train_dl\n",
    "\n",
    "def initValDl(val_ds, batch_size = BATCH_SIZE):\n",
    "    val_dl = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=USE_CUDA,\n",
    "    )\n",
    "    return val_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E26saJkd_CSC"
   },
   "source": [
    "# Set for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "XFCCB0Vs_tU-"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "log = logging.getLogger(\"3DUnet\")\n",
    "# log.setLevel(logging.WARN)\n",
    "# log.setLevel(logging.INFO)\n",
    "log.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "6M8rm4z0EB9P"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "# For logging \n",
    "trn_writer = None\n",
    "val_writer = None\n",
    "# TB_PREFIX = img_type + \"_fn0\"\n",
    "time_str = datetime.datetime.now().strftime('%Y-%m-%d_%H.%M.%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "lWgh1Szb-obt"
   },
   "outputs": [],
   "source": [
    "# Used for computeClassificationLoss and logMetrics to index into metrics_t/metrics_a\n",
    "# METRICS_LABEL_NDX = 0\n",
    "METRICS_LOSS_NDX = 1\n",
    "# METRICS_FN_LOSS_NDX = 2\n",
    "# METRICS_ALL_LOSS_NDX = 3\n",
    "\n",
    "# METRICS_PTP_NDX = 4\n",
    "# METRICS_PFN_NDX = 5\n",
    "# METRICS_MFP_NDX = 6\n",
    "METRICS_TP_NDX = 7\n",
    "METRICS_FN_NDX = 8\n",
    "METRICS_FP_NDX = 9\n",
    "\n",
    "METRICS_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7752,
     "status": "ok",
     "timestamp": 1626890472808,
     "user": {
      "displayName": "이정오",
      "photoUrl": "",
      "userId": "04886549528950007370"
     },
     "user_tz": -540
    },
    "id": "dZA_s68FvDKY",
    "outputId": "a2e787c2-21a9-4760-abbb-c48237c57876"
   },
   "outputs": [],
   "source": [
    "from torch.optim import SGD, AdamW, RMSprop\n",
    "from torch import nn\n",
    "from pytorch3dunet.unet3d.model import ResidualUNet3D, DropResidualUNet3D\n",
    "\n",
    "def initModel():    \n",
    "    segmentation_model = DropResidualUNet3D(in_channels=3, out_channels=4, num_groups=32, f_maps=32, testing=True, num_levels=LEVELS)\n",
    "\n",
    "    # augmentation_model = SegmentationAugmentation(**self.augmentation_dict)\n",
    "\n",
    "    if USE_CUDA:\n",
    "        log.info(\"Using CUDA; {} devices.\".format(torch.cuda.device_count()))\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            segmentation_model = nn.DataParallel(segmentation_model)\n",
    "            # augmentation_model = nn.DataParallel(augmentation_model)\n",
    "        segmentation_model = segmentation_model.to(DEVICE)\n",
    "        # augmentation_model = augmentation_model.to(DEVICE)\n",
    "\n",
    "    return segmentation_model #, augmentation_model\n",
    "\n",
    "def initOptimizer():\n",
    "    return AdamW(segmentation_model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "    # return SGD(segmentation_model.parameters(), lr=0.001, momentum=0.99)\n",
    "\n",
    "segmentation_model = initModel()\n",
    "optimizer = initOptimizer()\n",
    "\n",
    "# Load model\n",
    "if MODEL_TO_LOAD :\n",
    "  model_folder = os.path.join(BASE_DIR, 'models')\n",
    "  model_path = os.path.join(model_folder, MODEL_TO_LOAD)\n",
    "  seg_dict = torch.load(model_path, map_location='cpu')\n",
    "  if torch.cuda.device_count() > 1:\n",
    "    segmentation_model.module.load_state_dict(seg_dict['model_state'])\n",
    "  else:\n",
    "    segmentation_model.load_state_dict(seg_dict['model_state'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DropResidualUNet3D(\n",
       "  (encoders): ModuleList(\n",
       "    (0): Encoder(\n",
       "      (basic_module): DropResNetBlock(\n",
       "        (conv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(1, 3, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(3, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (non_linearity): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Encoder(\n",
       "      (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (basic_module): DropResNetBlock(\n",
       "        (conv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (non_linearity): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Encoder(\n",
       "      (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (basic_module): DropResNetBlock(\n",
       "        (conv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (non_linearity): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Encoder(\n",
       "      (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (basic_module): DropResNetBlock(\n",
       "        (conv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (non_linearity): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Encoder(\n",
       "      (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (basic_module): DropResNetBlock(\n",
       "        (conv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (non_linearity): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Encoder(\n",
       "      (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (basic_module): DropResNetBlock(\n",
       "        (conv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(512, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (non_linearity): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoders): ModuleList(\n",
       "    (0): Decoder(\n",
       "      (upsampling): TransposeConvUpsampling(\n",
       "        (upsample): ConvTranspose3d(1024, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      )\n",
       "      (basic_module): DropResNetBlock(\n",
       "        (conv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (non_linearity): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Decoder(\n",
       "      (upsampling): TransposeConvUpsampling(\n",
       "        (upsample): ConvTranspose3d(512, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      )\n",
       "      (basic_module): DropResNetBlock(\n",
       "        (conv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (non_linearity): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Decoder(\n",
       "      (upsampling): TransposeConvUpsampling(\n",
       "        (upsample): ConvTranspose3d(256, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      )\n",
       "      (basic_module): DropResNetBlock(\n",
       "        (conv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (non_linearity): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Decoder(\n",
       "      (upsampling): TransposeConvUpsampling(\n",
       "        (upsample): ConvTranspose3d(128, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      )\n",
       "      (basic_module): DropResNetBlock(\n",
       "        (conv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (non_linearity): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Decoder(\n",
       "      (upsampling): TransposeConvUpsampling(\n",
       "        (upsample): ConvTranspose3d(64, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      )\n",
       "      (basic_module): DropResNetBlock(\n",
       "        (conv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): SingleConv(\n",
       "          (groupnorm): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (non_linearity): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_conv): Conv3d(32, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  (final_activation): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentation_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141494538"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameters(segmentation_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "TeQVaciD_4zd"
   },
   "outputs": [],
   "source": [
    "from util.util import enumerateWithEstimate\n",
    "from monai.losses import DiceLoss\n",
    "\n",
    "def doTraining(epoch_ndx, train_dl):\n",
    "    trnMetrics_g = torch.zeros(METRICS_SIZE, len(train_dl.dataset), device=DEVICE)\n",
    "    segmentation_model.train()\n",
    "    # train_dl.dataset.shuffleSamples() - 정의에서 처리했음\n",
    "\n",
    "    batch_iter = enumerateWithEstimate(\n",
    "        train_dl,\n",
    "        \"E{} Training\".format(epoch_ndx),\n",
    "        start_ndx=train_dl.num_workers,\n",
    "    )\n",
    "    for batch_ndx, batch_tup in batch_iter:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_var = computeBatchLoss(batch_ndx, batch_tup, train_dl.batch_size, trnMetrics_g)\n",
    "        loss_var.backward()\n",
    "        \n",
    "        # Gradient clipping \n",
    "        max_norm = 5\n",
    "        torch.nn.utils.clip_grad_norm_(segmentation_model.parameters(), max_norm)\n",
    "        optimizer.step()\n",
    "    global totalTrainingSamples_count\n",
    "    totalTrainingSamples_count += trnMetrics_g.size(1)\n",
    "\n",
    "    return trnMetrics_g.to('cpu')\n",
    "\n",
    "def doValidation(epoch_ndx, val_dl):\n",
    "    with torch.no_grad():\n",
    "        valMetrics_g = torch.zeros(METRICS_SIZE, len(val_dl.dataset), device=DEVICE)\n",
    "        segmentation_model.eval()\n",
    "\n",
    "        batch_iter = enumerateWithEstimate(\n",
    "            val_dl,\n",
    "            \"E{} Validation \".format(epoch_ndx),\n",
    "            start_ndx=val_dl.num_workers,\n",
    "        )\n",
    "        for batch_ndx, batch_tup in batch_iter:\n",
    "            computeBatchLossVal(batch_ndx, batch_tup, val_dl.batch_size, valMetrics_g)\n",
    "\n",
    "    return valMetrics_g.to('cpu')\n",
    "\n",
    "def computeBatchLoss(batch_ndx, batch_tup, batch_size, metrics_g,\n",
    "                      classificationThreshold=0.5):\n",
    "    input_t, label_t= batch_tup\n",
    "    \n",
    "    input_g = input_t.to(DEVICE, non_blocking=True)\n",
    "    label_g = label_t.to(DEVICE, non_blocking=True).unsqueeze(1)\n",
    "\n",
    "    # if segmentation_model.training and augmentation_dict:\n",
    "    #     input_g, label_g = augmentation_model(input_g, label_g)\n",
    "\n",
    "    prediction_g_multi_ch = segmentation_model(input_g)\n",
    "#     prediction_g = prediction_g_multi_ch[:,0] # B, C, D, H, W -> B, D, H, W\n",
    "    prediction_g = prediction_g_multi_ch\n",
    "    diceLoss_g = diceLoss(prediction_g, label_g)\n",
    "    fnLoss_g = diceLoss(prediction_g * label_g, label_g)\n",
    "    ceLoss = nn.CrossEntropyLoss()\n",
    "    ceLoss_g = ceLoss(prediction_g, label_g.squeeze(1).long())\n",
    "    start_ndx = batch_ndx * batch_size\n",
    "    end_ndx = start_ndx + input_t.size(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictionBool_g = (prediction_g > classificationThreshold).to(torch.float32)\n",
    "\n",
    "        tp = (     predictionBool_g *  label_g).sum(dim=[1,2,3,4])\n",
    "        fn = ((1 - predictionBool_g) *  label_g).sum(dim=[1,2,3,4])\n",
    "        fp = (     predictionBool_g * (~label_g)).sum(dim=[1,2,3,4])\n",
    "\n",
    "        metrics_g[METRICS_LOSS_NDX, start_ndx:end_ndx] = diceLoss_g\n",
    "        metrics_g[METRICS_TP_NDX, start_ndx:end_ndx] = tp\n",
    "        metrics_g[METRICS_FN_NDX, start_ndx:end_ndx] = fn\n",
    "        metrics_g[METRICS_FP_NDX, start_ndx:end_ndx] = fp\n",
    "\n",
    "    return diceLoss_g.mean() + ceLoss_g + fnLoss_g.mean() * FN_LOSS \n",
    "\n",
    "def computeBatchLossVal(batch_ndx, batch_tup, batch_size, metrics_g,\n",
    "                      classificationThreshold=0.5):\n",
    "    input_t, label_t= batch_tup\n",
    "    \n",
    "    input_g = input_t.to(DEVICE, non_blocking=True)\n",
    "    label_g = label_t.to(DEVICE, non_blocking=True).unsqueeze(1)\n",
    "\n",
    "    prediction_g_multi_ch = segmentation_model(input_g)\n",
    "#     prediction_g = prediction_g_multi_ch[:,0] # B, C, D, H, W -> B, D, H, W\n",
    "    prediction_g = prediction_g_multi_ch\n",
    "    diceLoss_g = diceLoss(prediction_g, label_g)\n",
    "    start_ndx = batch_ndx * batch_size\n",
    "    end_ndx = start_ndx + input_t.size(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictionBool_g = (prediction_g > classificationThreshold).to(torch.float32)\n",
    "\n",
    "        tp = (     predictionBool_g *  label_g).sum(dim=[1,2,3,4])\n",
    "        fn = ((1 - predictionBool_g) *  label_g).sum(dim=[1,2,3,4])\n",
    "        fp = (     predictionBool_g * (~label_g)).sum(dim=[1,2,3,4])\n",
    "\n",
    "        metrics_g[METRICS_LOSS_NDX, start_ndx:end_ndx] = diceLoss_g\n",
    "        metrics_g[METRICS_TP_NDX, start_ndx:end_ndx] = tp\n",
    "        metrics_g[METRICS_FN_NDX, start_ndx:end_ndx] = fn\n",
    "        metrics_g[METRICS_FP_NDX, start_ndx:end_ndx] = fp\n",
    "\n",
    "    return diceLoss_g.mean()\n",
    "\n",
    "diceLoss = DiceLoss(to_onehot_y=True, include_background=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "UKwQWwI-xoGl",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def logMetrics(epoch_ndx, mode_str, metrics_t, tb_type = TB_PREFIX):\n",
    "    log.info(\"E{} {} {}\".format(\n",
    "        epoch_ndx,\n",
    "        \"Unet\",\n",
    "        tb_type\n",
    "    ))\n",
    "\n",
    "    metrics_a = metrics_t.detach().numpy()\n",
    "    sum_a = metrics_a.sum(axis=1)\n",
    "    assert np.isfinite(metrics_a).all()\n",
    "\n",
    "    allLabel_count = sum_a[METRICS_TP_NDX] + sum_a[METRICS_FN_NDX]\n",
    "\n",
    "    metrics_dict = {}\n",
    "    metrics_dict['loss/all'] = metrics_a[METRICS_LOSS_NDX].mean()\n",
    "\n",
    "    metrics_dict['percent_all/tp'] = \\\n",
    "        sum_a[METRICS_TP_NDX] / (allLabel_count or 1) * 100 \n",
    "    metrics_dict['percent_all/fn'] = \\\n",
    "        sum_a[METRICS_FN_NDX] / (allLabel_count or 1) * 100\n",
    "    metrics_dict['percent_all/fp'] = \\\n",
    "        sum_a[METRICS_FP_NDX] / (allLabel_count or 1) * 100\n",
    "\n",
    "\n",
    "    precision = metrics_dict['pr/precision'] = sum_a[METRICS_TP_NDX] \\\n",
    "        / ((sum_a[METRICS_TP_NDX] + sum_a[METRICS_FP_NDX]) or 1)\n",
    "    recall    = metrics_dict['pr/recall']    = sum_a[METRICS_TP_NDX] \\\n",
    "        / ((sum_a[METRICS_TP_NDX] + sum_a[METRICS_FN_NDX]) or 1)\n",
    "\n",
    "    metrics_dict['pr/f1_score'] = 2 * (precision * recall) \\\n",
    "        / ((precision + recall) or 1)\n",
    "\n",
    "    log.info((\"E{} {:8} \"\n",
    "              + \"{loss/all:.4f} loss, \"\n",
    "              + \"{pr/precision:.4f} precision, \"\n",
    "              + \"{pr/recall:.4f} recall, \"\n",
    "              + \"{pr/f1_score:.4f} f1 score\"\n",
    "              ).format(\n",
    "        epoch_ndx,\n",
    "        mode_str,\n",
    "        **metrics_dict,\n",
    "    ))\n",
    "    log.info((\"E{} {:8} \"\n",
    "              + \"{loss/all:.4f} loss, \"\n",
    "              + \"{percent_all/tp:-5.1f}% tp, {percent_all/fn:-5.1f}% fn, {percent_all/fp:-9.1f}% fp\"\n",
    "    ).format(\n",
    "        epoch_ndx,\n",
    "        mode_str + '_all',\n",
    "        **metrics_dict,\n",
    "    ))\n",
    "    global trn_writer\n",
    "    global val_writer\n",
    "    initTensorboardWriters()\n",
    "    if mode_str == 'trn':\n",
    "      writer = trn_writer\n",
    "    elif mode_str == 'pred':\n",
    "      writer = pred_writer\n",
    "    else:\n",
    "      writer = val_writer\n",
    "\n",
    "    prefix_str = 'seg_'\n",
    "\n",
    "    global totalTrainingSamples_count\n",
    "    for key, value in metrics_dict.items():\n",
    "        writer.add_scalar(prefix_str + key, value, totalTrainingSamples_count)\n",
    "\n",
    "    writer.flush()\n",
    "\n",
    "    score = metrics_dict['pr/recall']\n",
    "\n",
    "    return score\n",
    "\n",
    "import os\n",
    "\n",
    "LOG_DIR = os.path.join(BASE_DIR, 'logs')\n",
    "if not os.path.exists(LOG_DIR):\n",
    "  os.mkdir(LOG_DIR)\n",
    "  \n",
    "def initTensorboardWriters():\n",
    "    global trn_writer\n",
    "    global val_writer\n",
    "    global pred_writer\n",
    "    if trn_writer is None:\n",
    "        trn_writer = SummaryWriter(\n",
    "            log_dir= os.path.join(LOG_DIR, '{}_trn_seg_{}').format(TB_PREFIX, time_str) )\n",
    "        val_writer = SummaryWriter(\n",
    "            log_dir= os.path.join(LOG_DIR, '{}_val_seg_{}').format(TB_PREFIX, time_str) )\n",
    "#         pred_writer = SummaryWriter(\n",
    "#             log_dir= os.path.join(LOG_DIR, '{}_pred_seg_{}').format(TB_PREFIX, time_str) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install setuptools==59.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "vH1XOnNUHGJn"
   },
   "outputs": [],
   "source": [
    "def saveModel(type_str, epoch_ndx, tb_pre = TB_PREFIX):\n",
    "    model_name = '{}_model_epoch{}'.format(tb_pre, epoch_ndx)\n",
    "    file_path = os.path.join(\n",
    "        BASE_DIR,\n",
    "        'models',\n",
    "        model_name\n",
    "        )\n",
    "\n",
    "    os.makedirs(os.path.dirname(file_path), mode=0o755, exist_ok=True)\n",
    "\n",
    "    model = segmentation_model\n",
    "    if isinstance(model, torch.nn.DataParallel):\n",
    "        model = model.module\n",
    "\n",
    "    state = {\n",
    "        'sys_argv': sys.argv,\n",
    "        'time': str(datetime.datetime.now()),\n",
    "        'model_state': model.state_dict(),\n",
    "        'model_name': type(model).__name__,\n",
    "        'optimizer_state' : optimizer.state_dict(),\n",
    "        'optimizer_name': type(optimizer).__name__,\n",
    "        'epoch': epoch_ndx,\n",
    "        'totalTrainingSamples_count': totalTrainingSamples_count,\n",
    "    }\n",
    "    torch.save(state, file_path)\n",
    "    log.info(f\"Model was saved to {file_path}\")\n",
    "#     remote_location = 's3://{0}'.format(os.path.join(s3bucket, 'result/models', model_name))\n",
    "#     S3FS.put(file_path, remote_location)\n",
    "#     log.info(\"Saved model params to {} and remote S3 bucket\".format(file_path))\n",
    "\n",
    "    with open(file_path, 'rb') as f:\n",
    "        log.info(\"SHA1: \" + hashlib.sha1(f.read()).hexdigest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Pytorch 3D image tensor = Depth, Height, Weight\n",
    "#w(l-> r), h(t->b), d(u->d) 순서로군\n",
    "\n",
    "def pad_for_division(image, patch_size):\n",
    "    patch_d, patch_h, patch_w = patch_size \n",
    "    assert patch_d % 32 == 0 & patch_h % 32 == 0 & patch_w % 32 == 0, \"Patch size should be divided by 32\"\n",
    "    padding_d = patch_d - image.size(0)%patch_d\n",
    "    padding_h = patch_h - image.size(1)%patch_h\n",
    "    padding_w = patch_w - image.size(2)%patch_w\n",
    "    padded_image = F.pad(image, (0, padding_w, 0, padding_h, 0, padding_d))\n",
    "    return padded_image \n",
    "\n",
    "def pad_for_half(image, patch_size):\n",
    "    patch_d, patch_h, patch_w = patch_size \n",
    "    padded_image = F.pad(image, (patch_w//2, patch_w//2, patch_h//2, patch_h//2, patch_d//2, patch_d//2))\n",
    "    return padded_image \n",
    "\n",
    "    \n",
    "def adjust_window(image, window):\n",
    "    width = window[0]\n",
    "    level = window[1]\n",
    "    upper = level+width/2\n",
    "    lower = level-width/2\n",
    "    copied_image = image.clip(lower, upper)\n",
    "    copied_image = copied_image-lower\n",
    "    return (copied_image/(upper-lower))\n",
    "\n",
    "def convert_to_multi_channel_img(image, windows):\n",
    "    adjusted_images = [adjust_window(image, window) for window in windows]\n",
    "    return torch.stack(adjusted_images)\n",
    "\n",
    "# Process : padding -> adjust windows -> unfold -> neural network -> fold -> crop\n",
    "#           another padding -> adjust windows -> unfold -> neural network -> fold -> crop \n",
    "#           average all by 2 -> compare with the label. \n",
    "# 원래는 8개로 해야되는데, 간이 버전이라고 생각해볼 수 있겠음. \n",
    "\n",
    "def pred_image_with_model(padded_image, model, batch_size, patch_size):\n",
    "    '''\n",
    "    padded_image : image tensor with size of [D, H, W]\n",
    "    patch_size : tuple with size of 3\n",
    "    return pred_label : tensor with size of [D, H, W]\n",
    "    '''\n",
    "    windows = [(500,200), (700,400), (1200,400)]\n",
    "    input_channel = padded_image.size(0)\n",
    "    output_channel = 1\n",
    "    patch_d, patch_h, patch_w = patch_size \n",
    "    total_batch_size = batch_size * torch.cuda.device_count()\n",
    "\n",
    "    patches = padded_image.unfold(0, patch_d, patch_d).unfold(1, patch_h, patch_h).unfold(2, patch_w, patch_w)\n",
    "    unfold_shape = patches.size()\n",
    "    patches = patches.reshape(-1, patch_d, patch_h, patch_w)\n",
    "    \n",
    "    processed_patches = torch.zeros_like(patches)\n",
    "    iter_num = int(np.ceil(patches.size(0)/total_batch_size))\n",
    "    for i in range(iter_num):\n",
    "        start = i * total_batch_size\n",
    "        end = (i+1) * total_batch_size\n",
    "        batch = patches[start:end]\n",
    "        batch = convert_to_multi_channel_img(batch, windows)\n",
    "        batch = batch.permute(1,0,2,3,4)\n",
    "        proccessed_batch = model(batch).squeeze(1)\n",
    "        processed_patches[start:end] = proccessed_batch\n",
    "    \n",
    "    pred_patches = processed_patches.view(unfold_shape)\n",
    "    output_d = unfold_shape[0] * unfold_shape[3]\n",
    "    output_h = unfold_shape[1] * unfold_shape[4]\n",
    "    output_w = unfold_shape[2] * unfold_shape[5]\n",
    "    pred_patches = pred_patches.permute(0, 3, 1, 4, 2, 5)\n",
    "    pred_label = pred_patches.reshape(output_d, output_h, output_w)\n",
    "    return pred_label\n",
    "\n",
    "def predict_one_case(image_t, batch_size ,patch_size):\n",
    "    pad_image = pad_for_division(image_t, patch_size)\n",
    "    half_pad_image = pad_for_half(pad_image, patch_size)\n",
    "    d,h,w = image_t.shape\n",
    "    half_pad_d, half_pad_h, half_pad_w = [size//2 for size in patch_size]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        segmentation_model.eval()\n",
    "        pred_label = pred_image_with_model(pad_image, segmentation_model, batch_size, patch_size)\n",
    "        pred_half_pad_label = pred_image_with_model(half_pad_image, segmentation_model, batch_size, patch_size)\n",
    "        \n",
    "    cropped_pred = pred_label[:d, :h, :w]\n",
    "    cropped_pred_2 = pred_half_pad_label[half_pad_d:half_pad_d+d, half_pad_h:half_pad_h+h, half_pad_w:half_pad_w+w]\n",
    "    mean_pred = (cropped_pred + cropped_pred_2) / 2\n",
    "    return mean_pred\n",
    "\n",
    "\n",
    "def doPrediction(epoch_ndx, files, batch_size, patch_size):\n",
    "    log.info(\"E{} Prediction {}\".format(epoch_ndx, TB_PREFIX))\n",
    "    predMetrics_g = torch.zeros(METRICS_SIZE, len(files), device=DEVICE)\n",
    "    segmentation_model.eval()\n",
    "    \n",
    "    for i, file in enumerate(files):\n",
    "        image = np.load(get_img_path(file))\n",
    "        image_t = torch.tensor(image)\n",
    "        label = np.load(get_label_path(file))\n",
    "        \n",
    "        pred = predict_one_case(image_t, batch_size, patch_size)\n",
    "        pred_t = pred > 0.5 # classificationThreshold = 0.5\n",
    "        label_t = torch.tensor(label)\n",
    "        \n",
    "        predictionBool_g = pred_t.unsqueeze(0).to(torch.float32)\n",
    "        label_g = label_t.unsqueeze(0)\n",
    "        \n",
    "        diceLoss_g = diceLoss(predictionBool_g, label_g, epsilon=0.01)\n",
    "        fnLoss_g = diceLoss(predictionBool_g * label_g, label_g)\n",
    "\n",
    "        tp = (     predictionBool_g *  label_g).sum(dim=[1,2,3])\n",
    "        fn = ((1 - predictionBool_g) *  label_g).sum(dim=[1,2,3])\n",
    "        fp = (     predictionBool_g * (~label_g)).sum(dim=[1,2,3])\n",
    "        \n",
    "        predMetrics_g[METRICS_LOSS_NDX, i] = diceLoss_g # 차원 에러날듯 - i로 골라버리면 차원이 하나 줄기 때문.. 확인해봐야함. \n",
    "        predMetrics_g[METRICS_TP_NDX, i] = tp\n",
    "        predMetrics_g[METRICS_FN_NDX, i] = fn\n",
    "        predMetrics_g[METRICS_FP_NDX, i] = fp\n",
    "        \n",
    "    return predMetrics_g.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xamjgc4JFgtg"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 17:40:08,800 INFO     pid:1087760 3DUnet:001:<cell line: 1> Starting traning...\n"
     ]
    }
   ],
   "source": [
    "log.info(\"Starting traning...\")\n",
    "\n",
    "train_dl = initTrainDl(train_dataset)\n",
    "val_dl = initValDl(val_dataset)\n",
    "\n",
    "best_score = 0.0\n",
    "validation_cadence = 10\n",
    "pred_cadence = 20\n",
    "\n",
    "totalTrainingSamples_count = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 17:40:08,811 INFO     pid:1087760 3DUnet:002:<cell line: 1> Epoch 1 of 1000, 60/9 batches of size 4*1\n",
      "2022-08-01 17:40:08,815 WARNING  pid:1087760 util.util:219:enumerateWithEstimate E1 Training ----/60, starting\n"
     ]
    }
   ],
   "source": [
    "for epoch_ndx in range(1, 51):\n",
    "    log.info(\"Epoch {} of {}, {}/{} batches of size {}*{}\".format(\n",
    "        epoch_ndx,\n",
    "        EPOCHS,\n",
    "        len(train_dl),\n",
    "        len(val_dl),\n",
    "        BATCH_SIZE,\n",
    "        (torch.cuda.device_count() if USE_CUDA else 1),\n",
    "    ))\n",
    "\n",
    "    trnMetrics_t = doTraining(epoch_ndx, train_dl)\n",
    "\n",
    "    logMetrics(epoch_ndx, 'trn', trnMetrics_t)\n",
    "\n",
    "    if epoch_ndx == 1 or epoch_ndx % validation_cadence == 0:\n",
    "        # if validation is wanted\n",
    "        valMetrics_t = doValidation(epoch_ndx, val_dl)\n",
    "        score = logMetrics(epoch_ndx, 'val', valMetrics_t)\n",
    "        best_score = max(score, best_score)\n",
    "\n",
    "        # self.saveModel('seg', epoch_ndx, score == best_score)\n",
    "        saveModel('seg', epoch_ndx)\n",
    "        # self.logImages(epoch_ndx, 'trn', train_dl)\n",
    "        # self.logImages(epoch_ndx, 'val', val_dl)\n",
    "\n",
    "#     if epoch_ndx % pred_cadence ==0:\n",
    "#         predMetrics_t = doPrediction(epoch_ndx, VAL_FILES, batch_size=1, patch_size=(128,256,256))\n",
    "#         score = logMetrics(epoch_ndx, 'pred', predMetrics_t)\n",
    "        \n",
    "trn_writer.close()\n",
    "val_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in optimizer.param_groups:\n",
    "    g['lr'] = 0.0001\n",
    "    g['weight_decay'] = 0.00002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_ndx in range(51, 201):\n",
    "    log.info(\"Epoch {} of {}, {}/{} batches of size {}*{}\".format(\n",
    "        epoch_ndx,\n",
    "        EPOCHS,\n",
    "        len(train_dl),\n",
    "        len(val_dl),\n",
    "        BATCH_SIZE,\n",
    "        (torch.cuda.device_count() if USE_CUDA else 1),\n",
    "    ))\n",
    "\n",
    "    trnMetrics_t = doTraining(epoch_ndx, train_dl)\n",
    "\n",
    "    logMetrics(epoch_ndx, 'trn', trnMetrics_t)\n",
    "\n",
    "    if epoch_ndx == 1 or epoch_ndx % validation_cadence == 0:\n",
    "        # if validation is wanted\n",
    "        valMetrics_t = doValidation(epoch_ndx, val_dl)\n",
    "        score = logMetrics(epoch_ndx, 'val', valMetrics_t)\n",
    "        best_score = max(score, best_score)\n",
    "\n",
    "        # self.saveModel('seg', epoch_ndx, score == best_score)\n",
    "        saveModel('seg', epoch_ndx)\n",
    "        # self.logImages(epoch_ndx, 'trn', train_dl)\n",
    "        # self.logImages(epoch_ndx, 'val', val_dl)\n",
    "\n",
    "#     if epoch_ndx % pred_cadence ==0:\n",
    "#         predMetrics_t = doPrediction(epoch_ndx, VAL_FILES, batch_size=1, patch_size=(128,256,256))\n",
    "#         score = logMetrics(epoch_ndx, 'pred', predMetrics_t)\n",
    "        \n",
    "trn_writer.close()\n",
    "val_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in optimizer.param_groups:\n",
    "    g['lr'] = 0.00005\n",
    "    g['weight_decay'] = 0.00002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn(3, 5, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.empty(3, dtype=torch.long).random_(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([[1,2,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_ndx in range(201, 701):\n",
    "    log.info(\"Epoch {} of {}, {}/{} batches of size {}*{}\".format(\n",
    "        epoch_ndx,\n",
    "        EPOCHS,\n",
    "        len(train_dl),\n",
    "        len(val_dl),\n",
    "        BATCH_SIZE,\n",
    "        (torch.cuda.device_count() if USE_CUDA else 1),\n",
    "    ))\n",
    "\n",
    "    trnMetrics_t = doTraining(epoch_ndx, train_dl)\n",
    "\n",
    "    logMetrics(epoch_ndx, 'trn', trnMetrics_t)\n",
    "\n",
    "    if epoch_ndx == 1 or epoch_ndx % validation_cadence == 0:\n",
    "        # if validation is wanted\n",
    "        valMetrics_t = doValidation(epoch_ndx, val_dl)\n",
    "        score = logMetrics(epoch_ndx, 'val', valMetrics_t)\n",
    "        best_score = max(score, best_score)\n",
    "\n",
    "        # self.saveModel('seg', epoch_ndx, score == best_score)\n",
    "        saveModel('seg', epoch_ndx)\n",
    "        # self.logImages(epoch_ndx, 'trn', train_dl)\n",
    "        # self.logImages(epoch_ndx, 'val', val_dl)\n",
    "\n",
    "#     if epoch_ndx % pred_cadence ==0:\n",
    "#         predMetrics_t = doPrediction(epoch_ndx, VAL_FILES, batch_size=1, patch_size=(128,256,256))\n",
    "#         score = logMetrics(epoch_ndx, 'pred', predMetrics_t)\n",
    "        \n",
    "trn_writer.close()\n",
    "val_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in optimizer.param_groups:\n",
    "    g['lr'] = 0.00001\n",
    "    g['weight_decay'] = 0.000005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_ndx in range(701, EPOCHS + 1):\n",
    "    log.info(\"Epoch {} of {}, {}/{} batches of size {}*{}\".format(\n",
    "        epoch_ndx,\n",
    "        EPOCHS,\n",
    "        len(train_dl),\n",
    "        len(val_dl),\n",
    "        BATCH_SIZE,\n",
    "        (torch.cuda.device_count() if USE_CUDA else 1),\n",
    "    ))\n",
    "\n",
    "    trnMetrics_t = doTraining(epoch_ndx, train_dl)\n",
    "\n",
    "    logMetrics(epoch_ndx, 'trn', trnMetrics_t)\n",
    "\n",
    "    if epoch_ndx == 1 or epoch_ndx % validation_cadence == 0:\n",
    "        # if validation is wanted\n",
    "        valMetrics_t = doValidation(epoch_ndx, val_dl)\n",
    "        score = logMetrics(epoch_ndx, 'val', valMetrics_t)\n",
    "        best_score = max(score, best_score)\n",
    "\n",
    "        # self.saveModel('seg', epoch_ndx, score == best_score)\n",
    "        saveModel('seg', epoch_ndx)\n",
    "        # self.logImages(epoch_ndx, 'trn', train_dl)\n",
    "        # self.logImages(epoch_ndx, 'val', val_dl)\n",
    "\n",
    "#     if epoch_ndx % pred_cadence ==0:\n",
    "#         predMetrics_t = doPrediction(epoch_ndx, VAL_FILES, batch_size=1, patch_size=(128,256,256))\n",
    "#         score = logMetrics(epoch_ndx, 'pred', predMetrics_t)\n",
    "        \n",
    "trn_writer.close()\n",
    "val_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1626940740398,
     "user": {
      "displayName": "이정오",
      "photoUrl": "",
      "userId": "04886549528950007370"
     },
     "user_tz": -540
    },
    "id": "gB5Zd_kn8bes",
    "outputId": "ef387e03-fc9d-4803-ec21-91aa4b6f33ec",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls $BASE_DIR/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMGTa8s3ioYzkVicewqKqGu",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "BoneSegmentation_window_1300300_FN0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
